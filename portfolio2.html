<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simplified Portfolio - Saumik Dana</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">  
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
    .custom-image {
        width: 100%;
        margin-bottom: 0; /* Removes space below the image */
        padding-bottom: 0; /* Removes padding below the image */
    }     
    </style>  
</head>
<body>
    <header>
    <img src="saumik.jpg" alt="Profile Picture of Saumik Dana" class="profile-pic">
    <div class="header-text">
    <h1>Bayesian/MCMC on Time Series</h1>
    <a href="https://github.com/SaumikDana/Bayesian_MCMC_Deep-Learning" target="_blank" class="github-link">GitHub Repository</a>
    </div>
    <img src="montage3.webp" alt="Road Trips" class="profile-pic-right">
    </header>

    <main>
    <p>
    At USC, I spearheaded a project to develop a Bayesian inference 
    framework for model parameter estimation from time series data. 
    The challenge was to create a model that could accurately predict 
    and analyze complex data patterns. By employing Bayesian methods, 
    I was able to construct a framework that not only provided precise 
    estimations but also accounted for uncertainties in the data.
    </p>

    <h2>Bayesian Inference in Time Series Analysis</h2>
    <ul>
    <li><strong>Concept:</strong> Bayesian inference updates the probability of a model parameter's value based on observed time series data.</li>
    <li><strong>Process:</strong> It combines prior knowledge about the parameter (prior probability) with the likelihood of observing the data given the parameter values to produce an updated probability (posterior probability).</li>
    <li><strong>Bayes' Theorem:</strong> The process is governed by the formula \( P(\text{Parameter}|\text{Time Series}) = \frac{P(\text{Time Series}|\text{Parameter}) \times P(\text{Parameter})}{P(\text{Time Series})} \).</li>
    <li><strong>Application:</strong> This approach is particularly valuable in time series analysis for incorporating prior knowledge and handling complex, dynamic data.</li>
    </ul>

    <h2>Markov Chain Monte Carlo (MCMC) in Bayesian Time Series Analysis</h2>
    <ul>
    <li><strong>Purpose:</strong> MCMC is used to approximate the posterior distribution of a parameter when it's too complex to calculate directly in the context of time series data.</li>
    <li><strong>Method:</strong> It generates a series of samples through a Markov chain process, where the distribution of these samples converges to the posterior distribution of the parameter.</li>
    <li><strong>Algorithms:</strong> Includes techniques like Metropolis-Hastings and Gibbs sampling, tailored to explore the parameter space efficiently.</li>
    <li><strong>Utility:</strong> The samples from MCMC provide a way to estimate and understand the posterior distribution, allowing for predictions and uncertainty quantification in time series models.</li>
    </ul>
    
    <div class="image-section">
    <img src="montage_bayesian.png" alt="PhD Work" class="custom-image">
    </div>
    
    </main>

    <footer>
    <p>Copyright Â© 2023 by Saumik Dana</p>
    </footer>

</body>
</html>
