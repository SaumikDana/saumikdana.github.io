<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding SHAP: A Complete Guide</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #2c3e50;
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 30px;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
        }
        
        h2 {
            color: #e74c3c;
            font-size: 1.8em;
            margin-top: 40px;
            margin-bottom: 20px;
            padding: 10px;
            background: linear-gradient(90deg, #ffe0e0, transparent);
            border-left: 5px solid #e74c3c;
        }
        
        h3 {
            color: #27ae60;
            font-size: 1.4em;
            margin-top: 30px;
            margin-bottom: 15px;
        }
        
        .concept-box {
            background: #f8f9fa;
            border: 2px solid #3498db;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 5px 15px rgba(52, 152, 219, 0.1);
        }
        
        .formula {
            background: #2c3e50;
            color: white;
            padding: 15px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            margin: 15px 0;
            font-size: 1.1em;
            text-align: center;
        }
        
        .example {
            background: #fff3cd;
            border: 2px solid #ffc107;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .step {
            background: #e8f5e8;
            border-left: 5px solid #27ae60;
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 8px 8px 0;
        }
        
        .comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 30px 0;
        }
        
        .model-section {
            background: #f0f8ff;
            border: 2px solid #007bff;
            border-radius: 10px;
            padding: 25px;
        }
        
        .key-insight {
            background: #ffeaa7;
            border: 3px solid #fdcb6e;
            border-radius: 10px;
            padding: 20px;
            margin: 25px 0;
            font-weight: bold;
            text-align: center;
            font-size: 1.1em;
        }
        
        .matrix-display {
            font-family: 'Courier New', monospace;
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 15px 0;
            text-align: center;
            font-size: 1.1em;
        }
        
        ul, ol {
            padding-left: 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        .highlight {
            background: #fff3cd;
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Understanding SHAP: A Complete Guide</h1>
        
        <div class="concept-box">
            <h3>What is SHAP?</h3>
            <p><strong>SHAP (SHapley Additive exPlanations)</strong> explains machine learning predictions by decomposing them into contributions from each feature. It's based on game theory - specifically Shapley values from cooperative game theory.</p>
        </div>

        <h2>Step-by-Step Understanding</h2>

        <div class="step">
            <h3>Step 1: The Basic Question</h3>
            <p>Given a model prediction, SHAP answers: <em>"How much did each feature contribute to this specific prediction?"</em></p>
        </div>

        <div class="step">
            <h3>Step 2: The Decomposition</h3>
            <p>Every prediction is broken down as:</p>
            <div class="formula">
                f(x) = baseline + A_contribution + B_contribution + C_contribution
            </div>
            <p>Where:</p>
            <ul>
                <li><strong>f(x)</strong> = actual model prediction</li>
                <li><strong>baseline</strong> = same for all predictions</li>
                <li><strong>A_contribution</strong> = how much feature A helps/hurts</li>
                <li><strong>B_contribution</strong> = how much feature B helps/hurts</li>
                <li><strong>C_contribution</strong> = how much feature C helps/hurts</li>
            </ul>
        </div>

        <div class="step">
            <h3>Step 3: The Baseline</h3>
            <p>The baseline is the <span class="highlight">arithmetic mean</span> of all training predictions:</p>
            <div class="formula">
                baseline = (1/n) × sum of all model predictions on training data
            </div>
            <p>This is what the model predicts "on average".</p>
        </div>

        <div class="key-insight">
            🔑 Key Insight: The baseline is the same for all explanations. Only the feature contributions change from prediction to prediction.
        </div>

        <div class="step">
            <h3>Step 4: How to Get SHAP Values for Each Feature</h3>
            
            <h4>To get the SHAP value for feature A:</h4>
            <ol>
                <li><strong>A alone:</strong> f({A}) - f({}) = "How much does A help vs nothing?"</li>
                <li><strong>A with B:</strong> f({A,B}) - f({B}) = "How much does A help when B is present?"</li>
                <li><strong>A with C:</strong> f({A,C}) - f({C}) = "How much does A help when C is present?"</li>
                <li><strong>A with B,C:</strong> f({A,B,C}) - f({B,C}) = "How much does A help when B,C are present?"</li>
                <li><strong>Average these 4 numbers</strong> = SHAP value for A</li>
            </ol>

            <h4>To get the SHAP value for feature B:</h4>
            <ol>
                <li><strong>B alone:</strong> f({B}) - f({}) = "How much does B help vs nothing?"</li>
                <li><strong>B with A:</strong> f({A,B}) - f({A}) = "How much does B help when A is present?"</li>
                <li><strong>B with C:</strong> f({B,C}) - f({C}) = "How much does B help when C is present?"</li>
                <li><strong>B with A,C:</strong> f({A,B,C}) - f({A,C}) = "How much does B help when A,C are present?"</li>
                <li><strong>Average these 4 numbers</strong> = SHAP value for B</li>
            </ol>

            <h4>To get the SHAP value for feature C:</h4>
            <ol>
                <li><strong>C alone:</strong> f({C}) - f({}) = "How much does C help vs nothing?"</li>
                <li><strong>C with A:</strong> f({A,C}) - f({A}) = "How much does C help when A is present?"</li>
                <li><strong>C with B:</strong> f({B,C}) - f({B}) = "How much does C help when B is present?"</li>
                <li><strong>C with A,B:</strong> f({A,B,C}) - f({A,B}) = "How much does C help when A,B are present?"</li>
                <li><strong>Average these 4 numbers</strong> = SHAP value for C</li>
            </ol>
        </div>



        <h2>Linear Models: The Simple Case</h2>

        <div class="concept-box">
            <h3>Why Linear Models Are Special</h3>
            <p>For linear models, we don't need the complex averaging process! There's a direct formula.</p>
            
            <h4>Linear Model:</h4>
            <div class="formula">
                f(x) = coeff_A × A + coeff_B × B + coeff_C × C + intercept
            </div>
            
            <h4>SHAP Decomposition:</h4>
            <ul>
                <li><strong>Baseline:</strong> coeff_A × mean(A) + coeff_B × mean(B) + coeff_C × mean(C) + intercept</li>
                <li><strong>A contribution:</strong> coeff_A × (A - mean(A))</li>
                <li><strong>B contribution:</strong> coeff_B × (B - mean(B))</li>
                <li><strong>C contribution:</strong> coeff_C × (C - mean(C))</li>
            </ul>
        </div>

        <div class="step">
            <h3>How We Get the Linear Formula: Step by Step</h3>
            
            <p>Remember the general SHAP process? For feature A, we need to calculate:</p>
            <ol>
                <li>f({A}) - f({})</li>
                <li>f({A,B}) - f({B})</li>
                <li>f({A,C}) - f({C})</li>
                <li>f({A,B,C}) - f({B,C})</li>
                <li>Average these 4 contributions</li>
            </ol>
            
            <p><strong>Let's work this out for a linear model!</strong></p>
            <p>Model: f(A,B,C) = coeff_A × A + coeff_B × B + coeff_C × C + intercept</p>
            
            <h4>Step 1: Calculate each contribution</h4>
            
            <p><strong>Contribution 1:</strong> f({A}) - f({})</p>
            <ul>
                <li>f({A}) = coeff_A × A + coeff_B × mean(B) + coeff_C × mean(C) + intercept</li>
                <li>f({}) = coeff_A × mean(A) + coeff_B × mean(B) + coeff_C × mean(C) + intercept</li>
                <li>Difference = coeff_A × A - coeff_A × mean(A) = coeff_A × (A - mean(A))</li>
            </ul>
            
            <p><strong>Contribution 2:</strong> f({A,B}) - f({B})</p>
            <ul>
                <li>f({A,B}) = coeff_A × A + coeff_B × B + coeff_C × mean(C) + intercept</li>
                <li>f({B}) = coeff_A × mean(A) + coeff_B × B + coeff_C × mean(C) + intercept</li>
                <li>Difference = coeff_A × A - coeff_A × mean(A) = coeff_A × (A - mean(A))</li>
            </ul>
            
            <p><strong>Contribution 3:</strong> f({A,C}) - f({C})</p>
            <ul>
                <li>f({A,C}) = coeff_A × A + coeff_B × mean(B) + coeff_C × C + intercept</li>
                <li>f({C}) = coeff_A × mean(A) + coeff_B × mean(B) + coeff_C × C + intercept</li>
                <li>Difference = coeff_A × A - coeff_A × mean(A) = coeff_A × (A - mean(A))</li>
            </ul>
            
            <p><strong>Contribution 4:</strong> f({A,B,C}) - f({B,C})</p>
            <ul>
                <li>f({A,B,C}) = coeff_A × A + coeff_B × B + coeff_C × C + intercept</li>
                <li>f({B,C}) = coeff_A × mean(A) + coeff_B × B + coeff_C × C + intercept</li>
                <li>Difference = coeff_A × A - coeff_A × mean(A) = coeff_A × (A - mean(A))</li>
            </ul>
            
            <h4>Step 2: Average the contributions</h4>
            <div class="formula">
                A_contribution = (1/4) × [coeff_A × (A - mean(A)) + coeff_A × (A - mean(A)) + coeff_A × (A - mean(A)) + coeff_A × (A - mean(A))]<br>
                = (1/4) × [4 × coeff_A × (A - mean(A))]<br>
                = coeff_A × (A - mean(A))
            </div>
            
            <div class="key-insight">
                🎯 Amazing! All 4 contributions are identical for linear models, so the average is just coeff_A × (A - mean(A))!
            </div>
        </div>

        <div class="step">
            <h3>Why All 4 Contributions Are The Same</h3>
            <p>In every case, we're computing:</p>
            <ul>
                <li><strong>"Model with A"</strong> minus <strong>"Model without A"</strong></li>
                <li>The only difference is A vs mean(A)</li>
                <li>Everything else (B, C terms) cancels out perfectly!</li>
                <li>So we always get: coeff_A × (A - mean(A))</li>
            </ul>
            
            <p><strong>This is why linear models are special:</strong> Feature A's contribution doesn't depend on what other features are present!</p>
        </div>

        <div class="example">
            <h3>Step-by-Step Linear Example</h3>
            <p><strong>Model:</strong> Price = 50 × bedrooms + 100 × bathrooms + 200 × garage + 300</p>
            
            <h4>Training Data Averages:</h4>
            <ul>
                <li>mean(bedrooms) = 2.5</li>
                <li>mean(bathrooms) = 1.8</li>
                <li>mean(garage) = 0.6</li>
            </ul>
            
            <h4>House to Explain:</h4>
            <ul>
                <li>bedrooms = 3</li>
                <li>bathrooms = 2</li>
                <li>garage = 1</li>
            </ul>
            
            <h4>Model Prediction:</h4>
            <div class="formula">
                Price = 50×3 + 100×2 + 200×1 + 300 = 150 + 200 + 200 + 300 = 850
            </div>
            
            <h4>SHAP Breakdown:</h4>
            <ul>
                <li><strong>Baseline:</strong> 50×2.5 + 100×1.8 + 200×0.6 + 300 = 125 + 180 + 120 + 300 = 725</li>
                <li><strong>Bedrooms contribution:</strong> 50×(3-2.5) = 50×0.5 = 25</li>
                <li><strong>Bathrooms contribution:</strong> 100×(2-1.8) = 100×0.2 = 20</li>
                <li><strong>Garage contribution:</strong> 200×(1-0.6) = 200×0.4 = 80</li>
            </ul>
            
            <h4>Verification:</h4>
            <div class="formula">
                725 + 25 + 20 + 80 = 850 ✓
            </div>
            
            <h4>Interpretation:</h4>
            <ul>
                <li>"The model predicts 725 for an average house"</li>
                <li>"Having 3 bedrooms instead of 2.5 adds 25 to the price"</li>
                <li>"Having 2 bathrooms instead of 1.8 adds 20 to the price"</li>
                <li>"Having a garage instead of 0.6 probability adds 80 to the price"</li>
                <li>"Total: 725 + 25 + 20 + 80 = 850"</li>
            </ul>
        </div>

        <div class="key-insight">
            🔑 Key Insight: For linear models, SHAP is just coefficient × (actual_value - average_value). The coefficient tells you the rate of change, and the distance from average tells you how much to apply it!
        </div>

        <div class="concept-box">
            <h3>When computing f({A}), what do we do with B and C?</h3>
            <p>We have 3 options:</p>
            <ul>
                <li><strong>Option 1:</strong> Set B=0, C=0</li>
                <li><strong>Option 2:</strong> Set B=mean(B), C=mean(C)</li>
                <li><strong>Option 3:</strong> Average over all possible B,C values from training data</li>
            </ul>
            <p><strong>CRITICAL:</strong> Whatever option you choose, use it consistently for ALL calculations!</p>
        </div>

        <h2>Application to Different Models</h2>

        <div class="comparison">
            <div class="model-section">
                <h3>Linear Models</h3>
                <p><strong>Model:</strong> f(x) = coeff_A × A + coeff_B × B + intercept</p>
                
                <h4>SHAP Calculation (Simple!):</h4>
                <ul>
                    <li><strong>Baseline:</strong> coeff_A × mean(A) + coeff_B × mean(B) + intercept</li>
                    <li><strong>A contribution:</strong> coeff_A × (A - mean(A))</li>
                    <li><strong>B contribution:</strong> coeff_B × (B - mean(B))</li>
                </ul>
                
                <div class="example">
                    <h4>Example:</h4>
                    <p><strong>Model:</strong> Price = 3×bedrooms + 50×sqft + 100</p>
                    <p><strong>Training averages:</strong> bedrooms=2.5, sqft=15</p>
                    <p><strong>House:</strong> 3 bedrooms, 20 sqft</p>
                    <p><strong>Prediction:</strong> 3×3 + 50×20 + 100 = 1109</p>
                    
                    <p><strong>SHAP breakdown:</strong></p>
                    <ul>
                        <li>Baseline: 3×2.5 + 50×15 + 100 = 857.5</li>
                        <li>Bedrooms contribution: 3×(3-2.5) = 1.5</li>
                        <li>Sqft contribution: 50×(20-15) = 250</li>
                        <li>Check: 857.5 + 1.5 + 250 = 1109 ✓</li>
                    </ul>
                </div>
            </div>

            <div class="model-section">
                <h3>Nonlinear Models</h3>
                <p><strong>Model:</strong> Any complex model (trees, neural networks, etc.)</p>
                
                <h4>SHAP Calculation (Complex!):</h4>
                <p>Use the step-by-step process from Step 4 above, with approximation methods:</p>
                <ul>
                    <li><strong>TreeSHAP:</strong> Fast and exact for tree-based models</li>
                    <li><strong>KernelSHAP:</strong> Sampling approximation for any model</li>
                    <li><strong>DeepSHAP:</strong> For neural networks</li>
                </ul>
                
                <div class="example">
                    <h4>Example with Random Forest:</h4>
                    <p><strong>Model:</strong> Complex ensemble of decision trees</p>
                    <p><strong>House:</strong> 3 bedrooms, 20 sqft</p>
                    <p><strong>Prediction:</strong> $1,200 (from complex tree logic)</p>
                    
                    <p><strong>SHAP breakdown:</strong></p>
                    <ul>
                        <li>Baseline: $950 (average of all training predictions)</li>
                        <li>Bedrooms contribution: +$180 (calculated via TreeSHAP)</li>
                        <li>Sqft contribution: +$70 (calculated via TreeSHAP)</li>
                        <li>Check: $950 + $180 + $70 = $1,200 ✓</li>
                    </ul>
                </div>
            </div>
        </div>

        <h2>Key Differences Between Linear and Nonlinear</h2>

        <div class="concept-box">
            <h3>Linear Models</h3>
            <ul>
                <li>✅ <strong>Simple formula:</strong> A_contribution = coefficient × (A - mean(A))</li>
                <li>✅ <strong>Exact calculation:</strong> No approximation needed</li>
                <li>✅ <strong>Fast:</strong> Instant computation</li>
                <li>✅ <strong>Interpretable:</strong> Direct relationship to model coefficients</li>
            </ul>
        </div>

        <div class="concept-box">
            <h3>Nonlinear Models</h3>
            <ul>
                <li>⚙️ <strong>Complex calculation:</strong> Need to try all feature combinations</li>
                <li>⚙️ <strong>Approximation:</strong> Often uses sampling or other tricks</li>
                <li>⚙️ <strong>Slower:</strong> Can be computationally expensive</li>
                <li>✅ <strong>Flexible:</strong> Works with any model type</li>
            </ul>
        </div>

        <h2>The Universal SHAP Process</h2>

        <div class="step">
            <h3>For ANY model type:</h3>
            <ol>
                <li><strong>Train your model</strong> (linear, tree, neural network, etc.)</li>
                <li><strong>Calculate baseline:</strong> Average all training predictions</li>
                <li><strong>For each data point to explain:</strong>
                    <ul>
                        <li>Calculate A_contribution using the method above</li>
                        <li>Calculate B_contribution using the method above</li>
                        <li>Calculate C_contribution using the method above</li>
                    </ul>
                </li>
                <li><strong>Verify:</strong> baseline + A_contribution + B_contribution + C_contribution = actual prediction</li>
            </ol>
        </div>

        <div class="key-insight">
            🎯 Bottom Line: SHAP tells you exactly how much each feature A, B, C contributed to each prediction!
        </div>

        <h2>What SHAP Values Tell You</h2>

        <div class="concept-box">
            <h3>What you can learn:</h3>
            <ul>
                <li>✅ <strong>Which feature matters most:</strong> Is A_contribution bigger than B_contribution?</li>
                <li>✅ <strong>Direction of impact:</strong> Is A_contribution positive (helps) or negative (hurts)?</li>
                <li>✅ <strong>Exact magnitude:</strong> A_contribution = +$500 means feature A adds $500 to prediction</li>
                <li>✅ <strong>Feature ranking:</strong> Sort features by absolute contribution size</li>
            </ul>
        </div>

        <div class="concept-box">
            <h3>What you cannot learn:</h3>
            <ul>
                <li>❌ <strong>Causation:</strong> SHAP shows correlation, not causation</li>
                <li>❌ <strong>Global importance:</strong> These values are specific to this one prediction</li>
                <li>❌ <strong>Feature interactions:</strong> SHAP assumes features work independently</li>
            </ul>
        </div>

        <div class="key-insight">
            🔬 Remember: SHAP gives you baseline + A_contribution + B_contribution + C_contribution = prediction. One baseline + one value per feature per data point!
        </div>
    </div>
</body>
</html>
