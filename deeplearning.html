<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simplified Portfolio - Saumik Dana</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
    .content-container {
        display: flex;
        flex-direction: column;
        align-items: flex-start;
        gap: 20px;
    }

    .text-section, .image-section {
        width: 100%;
    }

    .image-section {
        flex-basis: auto;
    }

    .pointnet-image {
        margin-top: 0; /* Adjust this value as needed */
        width: 200%;
        max-width: 750px;
        height: auto;
        margin-bottom: 0; /* Adjust this value as needed */
    }
    
    .framework-steps {
        margin-top: 20px;
        padding: 15px;
        background-color: #f5f5f5;
        border-radius: 5px;
    }

    .framework-steps h2 {
        color: #333;
    }

    .framework-steps ol {
        padding-left: 20px;
    }

    .side-by-side-container {
        display: flex;
        align-items: center;
        justify-content: space-between;
        gap: 20px;
    }

    .side-by-side-container .text-section, 
    .side-by-side-container .image-section {
        flex: 1;
    }

    .side-by-side-container .image-section img {
        width: 100%;
        height: auto;
    }

    .custom-image {
        width: 50%;
        margin-top: 0;
        margin-bottom: 20px; /* Removes space below the image */
        padding-bottom: 0; /* Removes padding below the image */
    }     
    .custom-image1 {
        width: 60%;
        margin-left: 0;
        margin-top: 0;
        margin-bottom: 20px; /* Removes space below the image */
        padding-bottom: 0; /* Removes padding below the image */
    }     

    </style>
</head>
<body>
    <header>
    <img src="saumik.jpg" alt="Profile Picture of Saumik Dana" class="profile-pic">
    <div class="header-text">
    <h1>Point Cloud Processing with PointNet</h1>
    <a href="https://github.com/SaumikDana/DL_CV_Images" target="_blank" class="github-link">GitHub Repository</a>
    </div>
    <img src="montage2.webp" alt="PointNet" class="profile-pic-right">
    </header>
    <nav>
    <a href="classification.html" class="tablinks">Classification</a>
    <a href="segmentation.html" class="tablinks">Segmentation</a>
    <a href="registration.html" class="tablinks">Registration</a>
    </nav>
    <main>
    <p>
    During my recent stint at a surgical navigation startup, 
    while the company was cobbling a product demo, which I was heavily involved in, 
    I started looking at point clouds, and I embarked on a personal project to 
    leverage deep learning for point cloud processing. 
    </p>

    <section>
    <h2>Problems with CNNs</h2>
    
    <div class="image-section">
    <img src="fail_cnn.png" alt="PhD Work" class="custom-image">
    </div>
            
    <blockquote>
    "Just like many other famous technologies in deep learning, 
    the main challenge of a technology in deep leaning is probably invariance. 
    Invariance is tightly related to efficiency, both in training speed and data. 
    For example, CNN has translational invariance or equivariance, 
    which means if we translate an object in an image from place A to place B, 
    the learned object feature is also translated to place B. 
    Thank to this property, we need not translate an object from places to places 
    for data augmentation. However, CNN cannot be rotation invariance. 
    That ‘s why we have to rotate the input images for data augmentation during training. 
    In point clouds, other than the above two invariances, 
    we have to consider one more: permutation invariance, 
    in which the learned point cloud features are consistent 
    no matter how the points are stored in the input file. 
    Therefore, the three invariance challenges are: 
    translation invariance, rotation invariance, and permutation invariance."
    </blockquote>

    <div class="image-section">
    <img src="fail_cnn_tmi.png" alt="PhD Work" class="custom-image1">
    </div>
    
    <section>
    <h2>PointNet Architecture</h2>
    <div class="text-section">
    <img src="base_arch.png" alt="PointNet Basic Architecture" class="pointnet-image">
    </div>
    <div class="text-section">
    <img src="DL_PCD.png" alt="Deep Learning on PCD"  class="pointnet-image">
    </div>                    
    </section>

    <section>
    <h2>Datasets</h2>
    <ul>
    <li><strong>3DMatch:</strong> <a href="https://3dmatch.cs.princeton.edu/" target="_blank">3DMatch Dataset</a>
    - Focused on 3D reconstruction and matching. 
    It is a collection of 3D scans used to benchmark algorithms 
    for 3D surface reconstruction and to align 3D scans 
    in the field of computer vision. The primary goal of 3DMatch 
    is to facilitate the development and testing of algorithms 
    that can match and align 3D data from different sources or viewpoints.</li>
    <li><strong>ShapeNet:</strong> <a href="https://shapenet.org/" target="_blank">ShapeNet</a>
    - Large-scale, richly-annotated dataset of 3D shapes. 
    It's designed for various tasks like object recognition and segmentation 
    in the realm of computer vision and AI.</li>
    </ul>    
    </section>

    </main>
    <footer>
    <p>Copyright © 2023 by Saumik Dana</p>
    </footer>
</body>

</html>
